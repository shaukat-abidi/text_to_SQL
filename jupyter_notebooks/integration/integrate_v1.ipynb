{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "import pycrfsuite\n",
    "from jinja2 import Template\n",
    "\n",
    "import numpy as np\n",
    "import pickle\n",
    "import psycopg2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Text Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Pickle objects\n",
    "count_vect = CountVectorizer()\n",
    "tf_transformer = TfidfTransformer(use_idf=False)\n",
    "clf = MultinomialNB()\n",
    "\n",
    "open_file = open(\"classification.pkl\", \"rb\")\n",
    "count_vect, tfidf_transformer, clf = pickle.load(open_file)\n",
    "open_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['What patients in R3500-AD-1906 are from Germany ?']\n"
     ]
    }
   ],
   "source": [
    "# text = 'Which patients are registered in R3500-AD-1906 ?'\n",
    "text = 'What patients in R3500-AD-1906 are from Germany ?'\n",
    "docs_new = []\n",
    "docs_new.append(text)\n",
    "print(docs_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_new_counts = count_vect.transform(docs_new)\n",
    "X_new_tfidf = tfidf_transformer.transform(X_new_counts)\n",
    "\n",
    "predicted = clf.predict(X_new_tfidf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Which patients are registered in R3500-AD-1906 ? get_subjects\n"
     ]
    }
   ],
   "source": [
    "categories = ['get_subjects', 'get_study']\n",
    "#for doc, category in zip(docs_new, predicted):\n",
    "#print(doc, category, categories[category-1])\n",
    "sentence_category = categories[category-1]\n",
    "print(doc, sentence_category)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def word2features(sent, i):\n",
    "    word = sent[i][0]\n",
    "    features = [\n",
    "        'bias',\n",
    "        'word.lower=' + word.lower(),\n",
    "        'word[-3:]=' + word[-3:],\n",
    "        'word[-2:]=' + word[-2:],\n",
    "        'word.isupper=%s' % word.isupper(),\n",
    "        'word.istitle=%s' % word.istitle(),\n",
    "        'word.isdigit=%s' % word.isdigit(),\n",
    "        ]\n",
    "    if i > 0:\n",
    "        word1 = sent[i-1][0]\n",
    "        features.extend([\n",
    "            '-1:word.lower=' + word1.lower(),\n",
    "            '-1:word.istitle=%s' % word1.istitle(),\n",
    "            '-1:word.isupper=%s' % word1.isupper(),\n",
    "        ])\n",
    "    else:\n",
    "        features.append('BOS')\n",
    "        \n",
    "    if i < len(sent)-1:\n",
    "        word1 = sent[i+1][0]\n",
    "        features.extend([\n",
    "            '+1:word.lower=' + word1.lower(),\n",
    "            '+1:word.istitle=%s' % word1.istitle(),\n",
    "            '+1:word.isupper=%s' % word1.isupper(),\n",
    "        ])\n",
    "    else:\n",
    "        features.append('EOS')\n",
    "                \n",
    "    return features\n",
    "\n",
    "\n",
    "def sent2features(sent):\n",
    "    return [word2features(sent, i) for i in range(len(sent))]\n",
    "\n",
    "def sent2labels(sent):\n",
    "    return [label for token, label in sent]\n",
    "\n",
    "def sent2tokens(sent):\n",
    "    return [token for token, label in sent]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<contextlib.closing at 0x2ad99c14820>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tagger = pycrfsuite.Tagger()\n",
    "tagger.open('test.crfsuite')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['What', 'patients', 'in', 'R3500-AD-1906', 'are', 'from', 'Germany', '?']\n",
      "[('What', 'O'), ('patients', 'O'), ('in', 'O'), ('R3500-AD-1906', 'O'), ('are', 'O'), ('from', 'O'), ('Germany', 'O'), ('?', 'O')]\n",
      "['O', 'O', 'O', 'STUDYID', 'O', 'O', 'COUNTRY', 'O']\n"
     ]
    }
   ],
   "source": [
    "print(text.split())\n",
    "ner_input = [(tok, 'O') for tok in text.split()]\n",
    "print(ner_input)\n",
    "ner_output = tagger.tag(sent2features(ner_input))\n",
    "print(ner_output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SQL Generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "sql_template = {'get_subjects': 'select subjectid from subject_listing where',\n",
    "                'get_study': 'select studyid from study_listing where'}\n",
    "\n",
    "conditions = []\n",
    "for word, label in zip(ner_input, ner_output):\n",
    "    #print(word[0], label)\n",
    "    if label != str(\"O\"):\n",
    "        conditions.append(str(label) + '=' + str('\\'') + str(word[0]) + str('\\''))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "select subjectid from subject_listing where STUDYID='R3500-AD-1906' AND COUNTRY='Germany'\n"
     ]
    }
   ],
   "source": [
    "final_sql_condition = \" AND \".join(conditions)\n",
    "sql_query = str(sql_template[sentence_category]) + \" \" + final_sql_condition\n",
    "print(sql_query)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Query Database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Connect to your postgres DB\n",
    "conn = psycopg2.connect(\"dbname=postgres user=postgres password=postgres\")\n",
    "\n",
    "# Open a cursor to perform database operations\n",
    "cur = conn.cursor()\n",
    "\n",
    "# Execute a query\n",
    "cur.execute(sql_query)\n",
    "\n",
    "# Retrieve query results\n",
    "records = cur.fetchall()\n",
    "\n",
    "# Close the connection\n",
    "conn.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('1',), ('2',)]\n"
     ]
    }
   ],
   "source": [
    "print(records)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
